{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nils\\Anaconda3\\envs\\master2020\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nils\\Anaconda3\\envs\\master2020\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nils\\Anaconda3\\envs\\master2020\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nils\\Anaconda3\\envs\\master2020\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nils\\Anaconda3\\envs\\master2020\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nils\\Anaconda3\\envs\\master2020\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeries from: ./Test/SmallData.csv\n",
      " Header(labeled):\n",
      "    value  anomaly\n",
      "0  12183        0\n",
      "1  12715        0\n",
      "2  12736        0 \n",
      "Header(unlabeled):\n",
      "    value\n",
      "0  12183\n",
      "1  12715\n",
      "2  12736 \n",
      "Rows:\n",
      " 1439\n",
      "MeanValue:\n",
      " 11020.08\n",
      "MaxValue:\n",
      " 170029\n",
      "MinValue:\n",
      " 3594\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 24)                72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 50        \n",
      "=================================================================\n",
      "Total params: 1,322\n",
      "Trainable params: 1,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Successfully loaded Object from memory_binary_agent.obj\n",
      "Training episode 0 took 0.980419397354126 seconds Update Target Model\n",
      "Training episode 1 took 0.21042251586914062 seconds \n",
      "Training episode 2 took 0.23437213897705078 seconds \n",
      "Training episode 3 took 0.22936153411865234 seconds \n",
      "Training episode 4 took 0.2792646884918213 seconds \n",
      "Training episode 5 took 0.2922077178955078 seconds \n",
      "Training episode 6 took 0.3141598701477051 seconds \n",
      "Training episode 7 took 0.3361012935638428 seconds \n",
      "Training episode 8 took 0.3201453685760498 seconds \n",
      "Training episode 9 took 0.35205817222595215 seconds \n",
      "Training episode 10 took 0.36302947998046875 seconds Update Target Model\n",
      "Training episode 11 took 0.37400007247924805 seconds \n",
      "Training episode 12 took 0.3650243282318115 seconds \n",
      "Training episode 13 took 0.38796281814575195 seconds \n",
      "Training episode 14 took 0.36502790451049805 seconds \n",
      "Training episode 15 took 0.3979320526123047 seconds \n",
      "Training episode 16 took 0.4109017848968506 seconds \n",
      "Training episode 17 took 0.42685914039611816 seconds \n",
      "Training episode 18 took 0.3999307155609131 seconds \n",
      "Training episode 19 took 0.3779895305633545 seconds \n",
      "Training episode 20 took 0.4298744201660156 seconds Update Target Model\n",
      "Training episode 21 took 0.43581104278564453 seconds \n",
      "Training episode 22 took 0.42386722564697266 seconds \n",
      "Training episode 23 took 0.4248642921447754 seconds \n",
      "Training episode 24 took 0.44580864906311035 seconds \n",
      "Training episode 25 took 0.4328432083129883 seconds \n",
      "Training episode 26 took 0.46176576614379883 seconds \n",
      "Training episode 27 took 0.4468050003051758 seconds \n",
      "Training episode 28 took 0.42386698722839355 seconds \n",
      "Training episode 29 took 0.4388270378112793 seconds \n",
      "Training episode 30 took 0.4188809394836426 seconds Update Target Model\n",
      "Training episode 31 took 0.43483686447143555 seconds \n",
      "Training episode 32 took 0.4428417682647705 seconds \n",
      "Training episode 33 took 0.4467802047729492 seconds \n",
      "Training episode 34 took 0.44182300567626953 seconds \n",
      "Training episode 35 took 0.42188429832458496 seconds \n",
      "Training episode 36 took 0.4368162155151367 seconds \n",
      "Training episode 37 took 0.45079803466796875 seconds \n",
      "Training episode 38 took 0.43984460830688477 seconds \n",
      "Training episode 39 took 0.44179439544677734 seconds \n",
      "Training episode 40 took 0.4368593692779541 seconds Update Target Model\n",
      "Training episode 41 took 0.44278860092163086 seconds \n",
      "Training episode 42 took 0.4458119869232178 seconds \n",
      "Training episode 43 took 0.4527859687805176 seconds \n",
      "Training episode 44 took 0.4448111057281494 seconds \n",
      "Training episode 45 took 0.4198451042175293 seconds \n",
      "Training episode 46 took 0.4468057155609131 seconds \n",
      "Training episode 47 took 0.4527895450592041 seconds \n",
      "Training episode 48 took 0.44082117080688477 seconds \n",
      "Training episode 49 took 0.4328427314758301 seconds \n",
      "Training episode 50 took 0.4358353614807129 seconds Update Target Model\n",
      "Training episode 51 took 0.4408247470855713 seconds \n",
      "Training episode 52 took 0.43782663345336914 seconds \n",
      "Training episode 53 took 0.45079517364501953 seconds \n",
      "Training episode 54 took 0.4418189525604248 seconds \n",
      "Training episode 55 took 0.44281601905822754 seconds \n",
      "Training episode 56 took 0.40491747856140137 seconds \n",
      "Training episode 57 took 0.4527902603149414 seconds \n",
      "Training episode 58 took 0.45977044105529785 seconds \n",
      "Training episode 59 took 0.44082140922546387 seconds \n",
      "Training episode 60 took 0.4677927494049072 seconds Update Target Model\n",
      "Training episode 61 took 0.4198343753814697 seconds \n",
      "Training episode 62 took 0.43982982635498047 seconds \n",
      "Training episode 63 took 0.45278453826904297 seconds \n",
      "Training episode 64 took 0.45378661155700684 seconds \n",
      "Training episode 65 took 0.4408245086669922 seconds \n",
      "Training episode 66 took 0.42486143112182617 seconds \n",
      "Training episode 67 took 0.45575618743896484 seconds \n",
      "Training episode 68 took 0.4637608528137207 seconds \n",
      "Training episode 69 took 0.45378684997558594 seconds \n",
      "Training episode 70 took 0.45077061653137207 seconds Update Target Model\n",
      "Training episode 71 took 0.4198780059814453 seconds \n",
      "Training episode 72 took 0.46475744247436523 seconds \n",
      "Training episode 73 took 0.4478027820587158 seconds \n",
      "Training episode 74 took 0.4517960548400879 seconds \n",
      "Training episode 75 took 0.43882298469543457 seconds \n",
      "Training episode 76 took 0.4478034973144531 seconds \n",
      "Training episode 77 took 0.41788291931152344 seconds \n",
      "Training episode 78 took 0.4557816982269287 seconds \n",
      "Training episode 79 took 0.48569631576538086 seconds \n",
      "Training episode 80 took 0.44380974769592285 seconds Update Target Model\n",
      "Training episode 81 took 0.44882893562316895 seconds \n",
      "Training episode 82 took 0.43184542655944824 seconds \n",
      "Training episode 83 took 0.47572875022888184 seconds \n",
      "Training episode 84 took 0.5295841693878174 seconds \n",
      "Training episode 85 took 0.4857010841369629 seconds \n",
      "Training episode 86 took 0.47672486305236816 seconds \n",
      "Training episode 87 took 0.4657557010650635 seconds \n",
      "Training episode 88 took 0.4328422546386719 seconds \n",
      "Training episode 89 took 0.4717395305633545 seconds \n",
      "Training episode 90 took 0.5271036624908447 seconds Update Target Model\n",
      "Training episode 91 took 0.4587738513946533 seconds \n",
      "Training episode 92 took 0.48171234130859375 seconds \n",
      "Training episode 93 took 0.4747314453125 seconds \n",
      "Training episode 94 took 0.45879673957824707 seconds \n",
      "Training episode 95 took 0.4457852840423584 seconds \n",
      "Training episode 96 took 0.5364887714385986 seconds \n",
      "Training episode 97 took 0.485701322555542 seconds \n",
      "Training episode 98 took 0.4338393211364746 seconds \n",
      "Training episode 99 took 0.45799732208251953 seconds \n",
      "Testing episode 100 took 0.3958439826965332 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nils\\Anaconda3\\envs\\master2020\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1500x700 with 1 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agents.BinaryStateAgent import BinaryStateAgent\n",
    "from agents.MemoryBuffer import MemoryBuffer\n",
    "from agents.NeuralNetwork import NeuralNetwork\n",
    "from agents.Simulator import Simulator\n",
    "from environment.BinaryStateEnvironment import BinaryStateEnvironment\n",
    "from environment.Config import ConfigTimeSeries\n",
    "from environment.TimeSeriesModel import TimeSeriesEnvironment\n",
    "\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "config = ConfigTimeSeries(seperator=\",\", window=1)\n",
    "env = BinaryStateEnvironment(\n",
    "    TimeSeriesEnvironment(verbose=True, filename=\"./Test/SmallData.csv\", config=config, window=True))\n",
    "dqn = NeuralNetwork(input_dim=2,\n",
    "                    input_neurons=2 + 1).keras_model\n",
    "agent = BinaryStateAgent(dqn=dqn, memory=MemoryBuffer(max=5000, id=\"binary_agent\"), alpha=0.0001, gamma=0.9, \\\n",
    "                         epsilon=1.0, epsilon_end=0.0, epsilon_decay=0.9, fit_epoch=2, action_space=2, \\\n",
    "                         batch_size=512)\n",
    "simulation = Simulator(100, agent, env, 10)\n",
    "agent.memory.init_memory(env=env)\n",
    "simulation.run()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}